# -*- coding: utf-8 -*-
"""Breast_Cancer_Pred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x-f8OUpmezKrXTx-6qIEoaaXaQ1pBDG2

Importing the Dependencies
"""

import numpy as np
import pandas as pd
import sklearn.datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from sklearn.preprocessing import StandardScaler

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
from scipy import stats

"""Data Collection & Processing"""

# loading the data from sklearn
breast_cancer_dataset = sklearn.datasets.load_breast_cancer()

print(breast_cancer_dataset)

# loading the data to a data frame
data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)

# print the first 5 rows of the dataframe
data_frame.head()

# adding the 'target' column to the data frame
data_frame['label'] = breast_cancer_dataset.target

# print last 5 rows of the dataframe
data_frame.tail()

# number of rows and columns in the dataset
data_frame.shape

# getting some information about the data
data_frame.info()

# checking for missing values
data_frame.isnull().sum()

# statistical measures about the data
data_frame.describe()

df = pd.read_csv('/content/breast-cancer.csv')
plt.figure(figsize = (20, 6))
explode = (0,0.05)
counts =df['diagnosis'].value_counts()
counts
counts.plot(kind = 'pie', fontsize = 12, explode = explode, autopct = '%.1f%%')
plt.title('diagnosis')
plt.xlabel('diagnosis', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.ylabel('counts', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.legend(labels = counts.index, loc = "best")
plt.show()

import seaborn as sns
sns.heatmap(df.corr(numeric_only = True), cmap = 'YlGnBu')
plt.show()

sns.pairplot(df, vars = df.iloc[:, 2:11].columns, hue = 'diagnosis')
plt.show()

X = df.drop(columns=['diagnosis'])
y=df[['diagnosis']]

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X=scaler.fit_transform(X)

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

y_train = np.array(y_train).ravel()
y_test = np.array(y_test).ravel()

models = {
    'Logistic Regression': LogisticRegression(),
    'Support Vector Machine': SVC(),
    'Random Forest': RandomForestClassifier(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier()
}

y_test = np.array(y_test).ravel()

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, pos_label='B')
    recall = recall_score(y_test, y_pred, pos_label='B')
    f1 = f1_score(y_test, y_pred,pos_label = 'B')
    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}
results

for name, model in models.items():
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    print(f'Confusion Matrix for {name}:\n{cm}')

# cross-validation
from sklearn.model_selection import KFold

kf = KFold(n_splits=5, shuffle=True, random_state=123)

logreg = LogisticRegression(solver = 'liblinear', penalty = 'l2')
params = {'C':np.linspace(0.001, 1, 20), 'fit_intercept':[True, False]}
from sklearn.model_selection import GridSearchCV
logreg_cv = GridSearchCV(logreg, param_grid = params, cv = kf)
logreg_cv.fit(X_train, y_train)

print('Tuned Logistic Regression parameters : {}'.format(logreg_cv.best_params_))
print('Tuned Logistic Regression scores : {}'.format(logreg_cv.best_score_))

models = {
          'LogisticRegression':LogisticRegression(solver = 'liblinear', penalty = 'l2', C = 0.1061578947368421, fit_intercept = False),

         }
from sklearn.model_selection import cross_val_score

results = []
for model in models.values() :
    kf = KFold(n_splits = 5, shuffle = True, random_state = 123)
    cv_score = cross_val_score(model, X_train, y_train, cv = kf)
    results.append(cv_score)
print(results)

plt.boxplot(results, labels = models.keys())
plt.xlabel('Models')
plt.xticks(rotation = 45)
plt.ylabel('Accuracy score')
plt.title('Accuracy score of Breast Cancer prediction between Classifier models after cross-validation.')
plt.show()

# checking the distribution of Target Varibale
data_frame['label'].value_counts()

"""1 --> Benign

0 --> Malignant
"""

data_frame.groupby('label').mean()

"""Separating the features and target"""

X = data_frame.drop(columns='label', axis=1)
Y = data_frame['label']

print(X)

print(Y)

"""Splitting the data into training data & Testing data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Model Training

Logistic Regression
"""

model = LogisticRegression()

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Encode the target variable
Y_train_encoded = label_encoder.fit_transform(Y_train)

# Now, you can fit your model using the encoded target variable
model.fit(X_train, Y_train_encoded)

"""Model Evaluation

Accuracy Score
"""

# accuracy on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)

print('Accuracy on training data = ', training_data_accuracy)

# accuracy on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(Y_test, X_test_prediction)

print('Accuracy on test data = ', test_data_accuracy)

"""Building a Predictive System"""

input_data = (13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The Breast cancer is Malignant')

else:
  print('The Breast Cancer is Benign')